# README

Manuscript title: Combining Forecasts from Multiple Experts for Multiple Variables
Authors: Zhi Chen, Long Zhao


## Overview
**There are 5 folders with a detailed ReadMe file within each folder.** Here, we briefly introduce each folder.

### Code
The code for producing the empirical results in the paper.  

### M4RawData
Details of where to obtain the raw data for the M4 competitions and the corresponding data manipulation procedures. 

### M5RawData
Details of where to obtain the raw data for the M5 competitions and the corresponding data manipulation procedures. 

### CleanedData 
The data that are cleaned from the raw data.

### TeamIndex
The indexes of teams generated by solving the maximum diversity problem. 


## Instructions for Running the Code
**Please first install RStudio and then double click the 'Pool Inference.Rproj' file to open the project. It automatically sets the right working directory.**

## Detailed Descriptions

### Code Folder

#### Reproducibility
The results for the M4 and M5 datasets can be reproduced by running the files M4.R and M5.R, respectively. The M5.R script takes approximately 10 minutes to process a single set of teams (one table), whereas M4.R requires significantly more timeâ€”several days without parallel computation and several hours with it. However, parallel execution fails unpredictably on one of our Windows machines. To circumvent this issue, we provide a demo script (M4All.R) that runs the M4 dataset using all 17 teams and 119 variables. The results confirm that P:Linear consistently outperforms other benchmarks. 

The simulation results could be reproduced by running file simulation.R. This file also takes a long time to run. We include some instructions within the Rscript regarding how to reduce the computational time.

Figure 1 could be generated by running file Figure1.R

#### Data Manipulation
The code for processing the M4 and M5 datasets is available in the M4RawData and M5RawData folders, respectively. We also include instructions for downloading and storing the raw data. Additionally, preprocessed datasets are provided in the CleanedData folder for convenience.


#### File M4IdxGen.R and File M5IdxGen.R
These two files generate different selections of teams for forecast aggregation. Since solving the maximum diversity problem requires the gurobi package, which depends on a GUROBI solver license that users may not have, we have provided precomputed solutions in the TeamIndex folder.

#### File func.R 
This file contains all the functions needed in this repository. We provide some documentation to explain the functions, especially the ones that avoid large matrix multiplication when the number of products is massive.

### M4RawData Folder
This folder contains the raw data from the M4 Competition along with code for data manipulation. 

**File Organization:**
- Small files are included directly in this folder.
- Large files include download instructions and storage guidance.
- All data manipulation procedures are provided for reproducibility.

#### Data Files

##### Submission Information
**File:** `Submission Info.xlsx`  
**Description:** Contains participant rankings and competition results.  
**Source:** [M4 Methods GitHub - Point Forecasts](https://github.com/Mcompetitions/M4-methods/tree/master/Point%20Forecasts)

##### Training Data
**File:** `Hourly-train.csv`  
**Description:** Training dataset for hourly time series provided by competition organizers.  
**Source:** [M4 Methods GitHub - Train Dataset](https://github.com/Mcompetitions/M4-methods/tree/master/Dataset/Train)

##### Test Data
**File:** `Hourly-test.csv`  
**Description:** Test dataset for hourly time series provided by competition organizers.  
**Source:** [M4 Methods GitHub - Test Dataset](https://github.com/Mcompetitions/M4-methods/tree/master/Dataset/Test)

##### Series Metadata
**File:** `M4-info.csv`  
**Description:** Contains metadata about all time series including starting timestamps.  
**Source:** [M4 Methods GitHub - Main Dataset](https://github.com/Mcompetitions/M4-methods/tree/master/Dataset)

#### Data Manipulation Script

##### M4 Data Preparation
**File:** `M4DataManu.R`  
**Requirements:**
1. Download all submissions or the top 17 submissions (IDs: 005, 036, 039, 069, 072, 078, 104, 118, 132, 235, 237, 238, 243, 245, 250, 251, 260) from:  
   [M4 Methods GitHub - Point Forecasts](https://github.com/Mcompetitions/M4-methods/tree/master/Point%20Forecasts)
2. Unzip all of them in this folder.

**Methodology:**
- Implements data scaling using the Mean Absolute Scaled Error (MASE) methodology described in:  
  Makridakis et al. (2020). *The M4 Competition: 100,000 time series and 61 forecasting methods*.  
  International Journal of Forecasting, 36(1), 54-74.  
  DOI: [10.1016/j.ijforecast.2019.04.014](https://doi.org/10.1016/j.ijforecast.2019.04.014)

### M5RawData Folder
This folder contains the raw data from the M5 Competition along with code for data manipulation. 

**File Organization:**
- Small files are included directly in this folder.
- Large files include download instructions and storage guidance.
- All data manipulation procedures are provided for reproducibility.

#### Data Files

##### Test Set
**File:** `sales_test_evaluation.csv`  
**Description:** Test set provided by the competition organizers.
**Source:** [M5 Competition Google Drive - Dataset](https://drive.google.com/drive/folders/1wxz-TAfVE7uKGCjh405eCb2Q_pG3kAm9)

##### Weights of Time Series
**File:** `weights_evaluation.csv`  
**Description:** Weights of different time series provided by the competition organizers.
**Source:** [M5 Competition Google Drive - Dataset](https://drive.google.com/drive/folders/1wxz-TAfVE7uKGCjh405eCb2Q_pG3kAm9)


#### Data Manipulation Script

##### M5 Data Preparation
**File:** `M5DataManu.R`  
**Requirements:**
1. Download all submissions from:  
   [M5 Competition Google Drive - Accuracy Submissions](https://drive.google.com/drive/folders/1NZ1q8Z0gL20TED_W0Phv796MzwghOoPE)
2. Unzip all submissions directly in a subfolder called **Submissions**.
3. Download `sales_train_evaluation.csv` from [M5 Competition Google Drive - Dataset](https://drive.google.com/drive/folders/1wxz-TAfVE7uKGCjh405eCb2Q_pG3kAm9). 

**Methodology:**
- Implements data scaling using the Root Mean Squared Error (RMSE) methodology described in:  
  Makridakis et al. (2022). *M5 accuracy competition: Results, findings, and conclusions*.  
  International Journal of Forecasting, 38(4), 1346-1364.  
  DOI: [10.1016/j.ijforecast.2021.11.013](https://doi.org/10.1016/j.ijforecast.2021.11.013)

### CleanedData 
This folder contains preprocessed datasets for the M4 and M5 competitions.  
- **`M4.Rdata`**  
  - Generated using the cleaning procedures documented in the [`M4RawData`](../M4RawData) folder.  
- **`M5.Rdata`**  
  - Generated using the cleaning procedures documented in the [`M5RawData`](../M5RawData) folder.  

#### M4.Rdata
- It contains three data frames: data_test, f_data, and u_data.
   - data_test: the test data of all hourly time series with StartingDate being "1/7/15 12:00."
   - f_data: forecasts from top 17 experts for all hourly time series with StartingDate being "1/7/15 12:00."
   - u_data: forecast errors from top 17 experts for all hourly time series with StartingDate being "1/7/15 12:00."

#### M5.Rdata
- It contains four types of data frames: df_true, pred_all, scale2, and df_weight.
   - df_true_Lx: the test data of level x, where $1 \leq x \leq 9$.
   - pred_Lx_all: the predictions from all 50 experts for level x, where $1 \leq x \leq 9$.
   - scale2_Lx: the scaling factor of level x, where $1 \leq x \leq 9$.
      - It is the same scaling factor as in the root mean squared scaled error (RMSSE), which used in the M5 accuracy competition.
        [(Makridakis et al. 2022)](https://doi.org/10.1016/j.ijforecast.2021.11.013)
   - df_weight: the weight for each variable on each level.
      - It is the same weight vector as in weighted RMSSE (WRMSSE), which is used in the M5 accuracy competition. [(Makridakis et al. 2022)](https://doi.org/10.1016/j.ijforecast.2021.11.013)
- It also contains the information regarding the state, store, category, and department.

### TeamIndex
- Different team index file corresponding to different table in the paper. 
    - TopIdx2.Rdata: Table 5
    - TopIdx15.Rdata: Table 6
    - M4TopIdx2.Rdata: Table 7
    - M4TopIdx15.Rdata: Table 8
    - TopIdx3.Rdata: Table EC.1
    - TopIdx10.Rdata: Table EC.2
    - M4TopIdx3.Rdata: Table EC.3
    - M4TopIdx10.Rdata: Table EC.4    
    - MaxIdx2.Rdata: Table EC.5
    - MaxIdx15.Rdata: Table EC.6
    - M4MaxIdx2.Rdata: Table EC.7
    - M4MaxIdx15.Rdata: Table EC.8    
    - Max17Idx2.Rdata: Table EC.9
    - Max17Idx15.Rdata: Table EC.10
    
## Computational requirements
- We use R (version 4.4.1) and RStudio (version 2025.05.0+496) with the help of following packages.
	- tidyverse (2.0.0)
	- nlshrink (1.0.1)
	- MASS (7.3-61)
	- ggpubr (0.6.0)
	- xtable (1.8-4)
	- MCMCpack (1.7-0)
	- doparallel (1.0.17)
	- doRNG (1.8.6)
	- gurobi (optional, 10.0-1)
	- mvtnorm (1.2-5)


## Data Dictionary
Please see Data Dictionary.xlsx
